{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook represents the main notebook in which we showcase our main line of experiments. \\\n",
    "Please make sure to activate the environment before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "\n",
    "script_dir = os.path.abspath('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this notebook\n",
    "\n",
    "This notebook showcases the main experiments that we base our paper on. \n",
    "Our experimental setting is comprised of two main sets of experiments, namely:\n",
    "\n",
    "**i)** exploring the benefits of incorporating implicit topology in the EGNN framework, and \\\n",
    "**ii)** examining the trade-off between model complexity and the contribution of the topological information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We acknowledge that not anybody might have access to the required computational resources to train each of the models we tested, and thus we provide the saved model weights in the HuggingFace repository [here](https://huggingface.co/datasets/lucapantea/egnn-lspe/tree/main). We thus load each of the model weights saved during training in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create saved_models dir\n",
    "saved_models_dir = os.path.join(os.path.dirname(script_dir), 'saved_models')\n",
    "if not os.path.exists(saved_models_dir):\n",
    "    os.makedirs(saved_models_dir)\n",
    "\n",
    "# Load model weights from hugging face\n",
    "saved_models_dir_git = r'\"{}\"'.format(saved_models_dir)\n",
    "if os.path.exists(saved_models_dir) and len(os.listdir(saved_models_dir)) == 0:\n",
    "    !git clone https://huggingface.co/datasets/lucapantea/egnn-lspe {saved_models_dir_git}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B offline. Running your script from this directory will only write metadata locally. Use wandb disabled to completely turn off W&B.\n",
      "Namespace(evaluate='mpnn_qm9_fc_nope_no-lspe_yes-dist_no-reduced_no-update_with_pe_epochs-1000_num_layers-7_in_c-11_h_c-128_o_c-1_bs-96_lr-0.0005', model='mpnn', dataset='qm9_fc', pe='nope', pe_dim=24, lspe=False, seed=42, epochs=1000, batch_size=96, learning_rate=0.0005, weight_decay=1e-16, in_channels=11, hidden_channels=128, num_layers=7, out_channels=1, include_dist=True, reduced=False)\n",
      "MPS available. Setting device to MPS.\n",
      "Number of parameters: 743809\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/luca/Documents/Masters/Deep Learning 2/LSPE-EGNN/demos/../main.py\", line 304, in <module>\n",
      "    main(args)\n",
      "  File \"/Users/luca/Documents/Masters/Deep Learning 2/LSPE-EGNN/demos/../main.py\", line 289, in main\n",
      "    raise TypeError('Model path not recognized')\n",
      "TypeError: Model path not recognized\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /Users/luca/Documents/Masters/Deep Learning 2/LSPE-EGNN/demos/wandb/offline-run-20230524_115451-nk5fkywp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20230524_115451-nk5fkywp/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Experiment 1: Details, formulas, and running (either train or evaluate directly using model weights)\n",
    "# Use argument --evaluate to run experiments with the saved model weights\n",
    "!wandb offline\n",
    "!python ../main.py --evaluate \"mpnn_qm9_rw24_yes-lspe_no-dist_no-reduced_no-update_with_pe_epochs-1000_num_layers-7_in_c-11_h_c-128_o_c-1_bs-96_lr-0.0005_seed-420\" \\\n",
    "                   --dataset \"qm9\" --pe \"nope\" --include_dist --model \"mpnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2: Details, formulas, and running (either train or evaluate directly using model weights)\n",
    "# Use argument --evaluate to run experiments with the saved model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Studies?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
